{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3805fb3d",
   "metadata": {},
   "source": [
    "# FarmVibes.AI Sentinel/SpaceEye Demo\n",
    "This notebook demonstrates how FarmVibes.AI can be used to download and preprocess Sentinel data, as well as how to obtain cloud-free images using SpaceEye. We use workflows to investigate deforestation in the Amazon Rainforest in Brazil.\n",
    "\n",
    "### Conda environment setup\n",
    "To install the required packages, see [this README file](../README.md).\n",
    "\n",
    "------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb21278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import date, datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import geometry_window\n",
    "from shapely import geometry as shpg\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from vibe_core.client import get_default_vibe_client\n",
    "from vibe_notebook.plot import lw_plot, transparent_cmap\n",
    "from vibe_notebook.raster import read_raster, s1_to_img, s2_to_img, spaceeye_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb9d46",
   "metadata": {},
   "source": [
    "# Sentinel-2\n",
    "\n",
    "## Workflow input\n",
    "The workflows take as input a region, defined via a geometry in EPSG:4326 (`shapely` object), and a time range (tuple of `datetime`). For this example we select a region inside the Amazon Rainforest, in order to verify deforestation over five years. The region of interest is shown below, along with the Amazon biome borders, downloaded from [TerraBrasilis](http://terrabrasilis.dpi.inpe.br/en/home-page/), which is a platform built by INPE (National Institute for Space Research) for environmental monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input geometry: shapely object\n",
    "geom = shpg.Point(-55.252304077148445, -6.424483546180726).buffer(0.05, cap_style=3)\n",
    "# Time range: tuple of datetime. 3 month period in 2018\n",
    "time_range = (datetime(2018, 6, 1), datetime(2018, 9, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db723fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download biome borders to /tmp/amazon_shape\n",
    "!mkdir /tmp/amazon_shape\n",
    "!wget http://terrabrasilis.dpi.inpe.br/download/dataset/amz-aux/vector/amazon_biome_border.zip -O /tmp/amazon_shape/amazon_biome_border.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645a918",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\")).query(\"name == 'Brazil'\").boundary.plot(\n",
    "    ax=ax\n",
    ")\n",
    "gpd.read_file(\"/tmp/amazon_shape/amazon_biome_border.zip\").boundary.plot(ax=ax, color=\"C2\")\n",
    "gpd.GeoSeries(geom.centroid).plot(ax=ax, color=\"C1\")\n",
    "plt.legend([\"Brazil\", \"Amazon biome\", \"Region of Interest\"])\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6673390",
   "metadata": {},
   "source": [
    "## Downloading Sentinel-2 data\n",
    "Sentinel-2 related workflows have the prefix `data_ingestion/sentinel2`. To download a minimum set of products that cover the input region during the input time range, the `data_ingestion/sentinel2/preprocess_s2` workflow can be used. As with all other workflows, details about these workflows are available via the `document_workflow` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get client pointing to our local cluster\n",
    "client = get_default_vibe_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details about the workflow, such as inputs, output, and parameters\n",
    "client.document_workflow(\"data_ingestion/sentinel2/preprocess_s2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49262ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run(\n",
    "    \"data_ingestion/sentinel2/preprocess_s2\",\n",
    "    f\"Amazon {time_range[0].year}\",\n",
    "    geometry=geom,\n",
    "    time_range=time_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa7dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d8298",
   "metadata": {},
   "source": [
    "## Workflow outputs\n",
    "After the workflow is done, the outputs can be accessed via the `output` property. It is a dictionary, with keys being the `sink` names, as shown in the workflow documentation. For these workflows, the output rasters are available via the `raster` key. \n",
    "\n",
    "### Reading raster data\n",
    "Each raster contains an asset, which has a reference to a `tiff` file. The referenced file contains data for the whole tile (approx. 11k x 11k pixels at 10m resolution). The tiffs are tiled, so a portion of the image can be easily accessed without loading the whole file in memory. We use the `rasterio` library to read these rasters.\n",
    "\n",
    "The image below showcases a downloaded tile, as well as the input region of interest, shown in red.\n",
    "\n",
    "### Geometry projection\n",
    "All geometries used in FarmVibes.AI are in EPSG:4326, which is a geographic coordinate system. Sentinel-2 rasters are provided in local projected CRSs (UTM). Before using our input geometry to read from the raster, we must project it to the raster CRS. This can be done without reading any raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputs are the entire tiles, here is our input region in the tile\n",
    "s2 = run.output[\"raster\"][11]\n",
    "\n",
    "# A reference to the file can be obtained via `raster_asset.url`\n",
    "with rasterio.open(s2.raster_asset.url) as src:\n",
    "    # Get window (in pixels) from the geometry in the tiff (projected) CRS\n",
    "    proj_geom = gpd.GeoSeries(geom, crs=\"epsg:4326\").to_crs(src.crs).iloc[0].envelope\n",
    "    win = geometry_window(src, [proj_geom])\n",
    "    boxx, boxy = win.toranges()[::-1]\n",
    "    boxx = boxx + boxx[::-1] + boxx[:1]\n",
    "    boxy = tuple(b for b in boxy for _ in range(2)) + boxy[:1]\n",
    "    # Read the whole tile\n",
    "    ar = src.read()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(f\"Sentinel-2 tile: {s2.time_range[0].strftime('%Y-%m-%d')}\")\n",
    "    # Subsample the image by 10 for plotting\n",
    "    plt.imshow(s2_to_img(ar[:, ::10, ::10]))\n",
    "    plt.plot([b / 10 for b in boxx], [b / 10 for b in boxy], \"r\")\n",
    "    lw_plot()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(s2_to_img(read_raster(s2, geom)[0]))\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24583bbb",
   "metadata": {},
   "source": [
    "## Working with cloud masks\n",
    "In order to compute better cloud masks, the `data_ingestion/sentinel2/preprocess_s2_improved_masks` workflow also runs machine learning models over the image pixels to improve the product masks. This results in more accurate masks, but takes longer to run. It is recommended to use improved masks when cloud masks are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaffae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.document_workflow(\"data_ingestion/sentinel2/preprocess_s2_improved_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af9e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run2 = client.run(\n",
    "    \"data_ingestion/sentinel2/preprocess_s2_improved_masks\",\n",
    "    f\"Amazon {time_range[0].year}\",\n",
    "    geometry=geom,\n",
    "    time_range=time_range,\n",
    ")\n",
    "run2.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7b991",
   "metadata": {},
   "source": [
    "## Visualizing cloud masks\n",
    "Let's visualize the cloud masks overlaid on the Sentinel-2 image to showcase the difference in masks quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16270c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idxs = [2, 5, 6]\n",
    "for idx in idxs:\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(s2_to_img(read_raster(run.output[\"raster\"][idx], geom)[0]))\n",
    "    plt.imshow(\n",
    "        read_raster(run.output[\"mask\"][idx], geom)[0][0],\n",
    "        cmap=transparent_cmap(plt.cm.viridis),\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.title(\"Overlaid product mask\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(s2_to_img(read_raster(run.output[\"raster\"][idx], geom)[0]))\n",
    "    plt.imshow(\n",
    "        read_raster(run2.output[\"mask\"][idx], geom)[0][0],\n",
    "        cmap=transparent_cmap(plt.cm.viridis),\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "    )\n",
    "    plt.title(\"Overlaid improved mask\")\n",
    "    plt.axis(\"off\")\n",
    "    lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b0f5e2",
   "metadata": {},
   "source": [
    "## Cloud cover\n",
    "Cloud masks can be used to select cloud-free images automatically, or mask out cloudy regions during aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rasters with less than 10% of cloudy pixels\n",
    "cloud_thr = 0.1\n",
    "cloud_ratio = [read_raster(c, geom, filled=False)[0].mean() for c in tqdm(run2.output[\"mask\"])]\n",
    "cloud_free_rasters = [s2 for s2, c in zip(run.output[\"raster\"], cloud_ratio) if c < cloud_thr]\n",
    "cloudy_rasters = [s2 for s2, c in zip(run.output[\"raster\"], cloud_ratio) if c >= cloud_thr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3ba079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cloud cover\")\n",
    "for x, y in zip(run2.output[\"mask\"], cloud_ratio):\n",
    "    print(f\"{x.time_range[0].strftime('%Y-%m-%d')}: {y:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the cloud-free rasters\n",
    "N = 6\n",
    "S = 4\n",
    "H = math.ceil(len(cloud_free_rasters) / S)\n",
    "plt.figure(figsize=(N * S, H * S))\n",
    "for i, r in enumerate(cloud_free_rasters):\n",
    "    plt.subplot(H, N, i + 1)\n",
    "    plt.imshow(s2_to_img(read_raster(r, geom)[0]))\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Cloud-free Images\", fontsize=22)\n",
    "plt.tight_layout()\n",
    "lw_plot()\n",
    "# And cloudy ones\n",
    "H = math.ceil(len(cloudy_rasters) / S)\n",
    "plt.figure(figsize=(N * S, H * S))\n",
    "for i, r in enumerate(cloudy_rasters):\n",
    "    plt.subplot(H, N, i + 1)\n",
    "    plt.imshow(s2_to_img(read_raster(r, geom)[0]))\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Cloudy Images\", fontsize=22)\n",
    "plt.tight_layout()\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881b8d3",
   "metadata": {},
   "source": [
    "## VIsualizing deforestation over the years\n",
    "We'll now run the same workflow over 5 years to check the effects of deforestation on the area. For each year, we can select a cloud-free image and compare the changes at an approximate one-year interval. We'll submit 5 different workflow runs, one for each year time range. Since we have already run the worklfow for 2018, no computation will be performed (all the outputs will be fetched from the cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time ranges: 3 month periods for each year, from 2018 to 2022\n",
    "time_ranges = [(datetime(year, 6, 1), datetime(year, 9, 1)) for year in range(2018, 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277c55d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Request one workflow run per time range\n",
    "runs = [\n",
    "    client.run(\n",
    "        \"data_ingestion/sentinel2/preprocess_s2_improved_masks\",\n",
    "        f\"Amazon {tr[0].year}\",\n",
    "        geometry=geom,\n",
    "        time_range=tr,\n",
    "    )\n",
    "    for tr in time_ranges\n",
    "]\n",
    "client.monitor(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eff811",
   "metadata": {},
   "source": [
    "### Available imagery over the 3-month period\n",
    "Let's first check the available imagery for each time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee850f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "plot_idx = 1\n",
    "for i in range(0, min([len(r.output[\"raster\"]) for r in runs]), 3):\n",
    "    for j, r in enumerate(runs):\n",
    "        s2 = r.output[\"raster\"][i]\n",
    "        ar, _ = read_raster(s2, geom)\n",
    "        plt.subplot(6, 5, plot_idx)\n",
    "        plt.title(s2.time_range[0].strftime(\"%Y-%m-%d\"))\n",
    "        plt.imshow(s2_to_img(ar))\n",
    "        plt.axis(\"off\")\n",
    "        plot_idx += 1\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace74424",
   "metadata": {},
   "source": [
    "### Deforestation effects\n",
    "On the images below, we highlight visible signs of deforestation in the highlighted area. While no change is seen from 2018 to 2019, every year after shows increased deforestation. Note the road going deeper into the forest at each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddeeeae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = proj_geom.bounds\n",
    "focus_geom = shpg.box(xmin + 3000, ymax - 4000, xmax, ymax)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "s2 = runs[0].output[\"raster\"][11]\n",
    "ar = s2_to_img(read_raster(s2, geom)[0])\n",
    "plt.imshow(ar)\n",
    "plt.plot([300, ar.shape[1], ar.shape[1], 300, 300], [0, 0, 400, 400, 0], color=\"red\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"{s2.time_range[0].strftime('%Y-%m-%d')}\")\n",
    "lw_plot()\n",
    "for run in runs:\n",
    "    s2 = run.output[\"raster\"][11]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(s2_to_img(read_raster(s2, projected_geometry=focus_geom)[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{s2.time_range[0].strftime('%Y-%m-%d')}\")\n",
    "    lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e6b5b",
   "metadata": {},
   "source": [
    "# Sentinel-1\n",
    "The Sentinel-1 mission is comprised of satellites that carry a synthetic-aperture radar (SAR) instrument. This allows it to collect data in any weather condition, as the radar signal penetrates clouds. Below we show case how one might use FarmVibes.AI to download and preprocess Sentinel-1 data into Sentinel-2 aligned tiles. These aligned images can be used by the SpaceEye model to inpaint cloudy regions.\n",
    "\n",
    "## Download and preprocessing\n",
    "Sentinel-1 data is provided in a different tiling system than Sentinel-2. FarmVibes.AI preprocessing workflows will download the necessary data and preprocess it in order to generate Sentinel-1 data in the Sentinel-2 grid.\n",
    "\n",
    "### Sentinel-1 product selection\n",
    "The workflow will automatically select the necessary products in order to cover the Sentinel-2 tile. It will then preprocess and merge that information, in order to generate a Sentinel-1 image in the necessary Sentinel-2 tiles. Below is an example of the S1 tiles that intersect with out S2 tile of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"list_s1.yaml\") as f:\n",
    "    wf_dict = yaml.safe_load(f)\n",
    "\n",
    "s1_list_run = client.run(\n",
    "    wf_dict, \"S1 Products\", geometry=geom, time_range=time_range\n",
    ")  # .block_until_complete()\n",
    "s1_list_run.monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac268103",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "gpd.GeoSeries(\n",
    "    [shpg.shape(x.geometry) for x in s1_list_run.output[\"s1_products\"][:5]]\n",
    ").boundary.plot(ax=ax)\n",
    "gpd.GeoSeries([shpg.shape(x.geometry) for x in run.output[\"raster\"]]).boundary.plot(\n",
    "    ax=ax, color=\"C2\"\n",
    ")\n",
    "gpd.GeoSeries(geom).boundary.plot(ax=ax, color=\"C3\")\n",
    "plt.legend([\"Sentinel-1 footprints\", \"Sentinel-2 footprint\", \"Input region\"])\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639097f",
   "metadata": {},
   "source": [
    "## Preprocessing workflow\n",
    "The `data_ingestion/spaceeye/spaceeye_preprocess` workflow will download and preprocess all Sentinel-1 and Sentinel-2 data available for the input time range. It will also generate the improved cloud masks described previously. The Sentinel-1 data will be available in the same tiles as Sentinel-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ef960",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.document_workflow(\"data_ingestion/spaceeye/spaceeye_preprocess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_run = client.run(\n",
    "    \"data_ingestion/spaceeye/spaceeye_preprocess\",\n",
    "    \"SpaceEye Preprocess Amazon 2018\",\n",
    "    geometry=geom,\n",
    "    time_range=time_range,\n",
    ")\n",
    "s1_run.monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e741f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile information is also present in the Sentinel-1 rasters\n",
    "print(s1_run.output[\"s1_raster\"][0].tile_id)\n",
    "print(s1_run.output[\"s2_raster\"][0].tile_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784aacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_run.output.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5d9a0",
   "metadata": {},
   "source": [
    "Below are the available imagery from both Sentinel-1 and Sentinel-2. Note that they are available at different dates, due to them being captured by different platforms. Also see that while cloud coverage is clearly visible in Sentinel-2, weather effects do not interfere with Sentinel-1 imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c20e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s1_rasters = sorted(s1_run.output[\"s1_raster\"], key=lambda x: x.time_range[0])\n",
    "s2_rasters = sorted(s1_run.output[\"s2_raster\"], key=lambda x: x.time_range[0])\n",
    "\n",
    "N = 6\n",
    "S = 3\n",
    "H = math.ceil(len(s1_rasters) / N)\n",
    "plt.figure(figsize=(N * S, H * S))\n",
    "for i, r in enumerate(s1_rasters):\n",
    "    plt.subplot(H, N, i + 1)\n",
    "    plt.imshow(s1_to_img(read_raster(r, geom)[0]))\n",
    "    plt.title(r.time_range[0].strftime(\"%Y-%m-%d\"), fontsize=18)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Sentinel-1\", fontsize=22, y=0.99)\n",
    "plt.tight_layout()\n",
    "lw_plot()\n",
    "\n",
    "H = math.ceil(len(s2_rasters) / N)\n",
    "plt.figure(figsize=(N * S, H * S))\n",
    "for i, r in enumerate(s2_rasters):\n",
    "    plt.subplot(H, N, i + 1)\n",
    "    plt.imshow(s2_to_img(read_raster(r, geom)[0]))\n",
    "    plt.title(r.time_range[0].strftime(\"%Y-%m-%d\"), fontsize=18)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Sentinel-2\", fontsize=22, y=0.99)\n",
    "plt.tight_layout()\n",
    "lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff09456",
   "metadata": {},
   "source": [
    "Here is a close up of two days for which there are both Sentinel-1 and Sentinel-2 images. We can see that for cloudy and cloudless days the Sentinel-1 image remains unaffected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx1, idx2 in zip((7, 1), (6, 0)):\n",
    "    s1 = s1_run.output[\"s1_raster\"][idx1]\n",
    "    s2 = s1_run.output[\"s2_raster\"][idx2]\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(s2.time_range[0].isoformat())\n",
    "    plt.imshow(s2_to_img(read_raster(s2, geom)[0]))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(s1.time_range[0].isoformat())\n",
    "    plt.imshow(s1_to_img(read_raster(s1, geom)[0]))\n",
    "    plt.tight_layout()\n",
    "    lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1643f9",
   "metadata": {},
   "source": [
    "# SpaceEye\n",
    "SpaceEye is a technique that fuses both Sentinel-1 and Sentinel-2 data in order to generate daily cloud-free Sentinel-2 imagery. It uses a neural network to map sequences of Sentinel-1 and Sentinel-2 images into a sequence of cloud-free Sentinel-2 images. More information about SpaceEye is available in [the paper](https://arxiv.org/abs/2106.08408). The model operates on a spatio-temporal window (48 days and 448x448 pixels at 10m resolution, by default). The platform will automatically split the input data, perform inference over each window, and merge the results into a series of rasters. This step not performed at the tile level, like the former ops, so the output will be just for our input geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_run = client.run(\n",
    "    \"data_ingestion/spaceeye/spaceeye\", \"SpaceEye Amazon 2018\", geometry=geom, time_range=time_range\n",
    ")\n",
    "se_run.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28f464f",
   "metadata": {},
   "source": [
    "## Daily imagery\n",
    "While Sentinel-2 images are available at an approximate 5-day interval, the SpaceEye model performs temporal interpolation and generates images daily in the input interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1956173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily imagery\n",
    "print(f\"Sentinel-2 rasters: {len(runs[0].output['raster'])}\")\n",
    "print(f\"SpaceEye rasters: {len(se_run.output['raster'])}\")\n",
    "\n",
    "for r, rgb_idx, name in zip(\n",
    "    (se_run.output[\"raster\"], runs[0].output[\"raster\"]),\n",
    "    ([2, 1, 0], [3, 2, 1]),\n",
    "    (\"SpaceEye\", \"Sentinel-2\"),\n",
    "):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i in range(1, 7):\n",
    "        plt.subplot(1, 6, i)\n",
    "        ref_date = date(2018, 6, i + 10)\n",
    "        match_raster = [rr for rr in r if rr.time_range[0].date() == ref_date]\n",
    "        if match_raster:\n",
    "            match_ar = s2_to_img(read_raster(match_raster[0], geom)[0], rgb_idx=rgb_idx)\n",
    "            plt.imshow(match_ar)\n",
    "\n",
    "        else:\n",
    "            plt.imshow(no_data)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(ref_date.strftime(\"%Y-%m-%d\"))\n",
    "    plt.suptitle(f\"{name}\")\n",
    "    lw_plot()\n",
    "    no_data = np.zeros_like(match_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d24312",
   "metadata": {},
   "source": [
    "## Cloud inpainting\n",
    "Below is a comparison of some days for which Sentinel-2 images are available. SpaceEye reconstructs regions occluded by clouds and cloud shadows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5778c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s2 in sorted(runs[0].output[\"raster\"][::2], key=lambda x: x.time_range[0]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    se_raster = sorted(\n",
    "        se_run.output[\"raster\"], key=lambda x: abs(s2.time_range[0] - x.time_range[0])\n",
    "    )[0]\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(s2.time_range[0].strftime(\"%Y-%m-%d\"))\n",
    "    plt.imshow(s2_to_img(read_raster(s2, geom)[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spaceeye_to_img(read_raster(se_raster)[0]))\n",
    "    plt.title(\"SpaceEye\")\n",
    "    plt.axis(\"off\")\n",
    "    lw_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f395c",
   "metadata": {},
   "source": [
    "# Inpainting via damped interpolation\n",
    "There is a second SpaceEye method for generating daily cloud-free images available at FarmVibes.AI. It is based on temporal damped interpolation of cloud-free pixels. This method does not fuse Sentinel-1 data, relying solely on cloud-free Sentinel-2 data to inpaint pixels. It can be accessed via the `data_ingestion/spaceeye/spaceeye_interpolation` workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5324cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_interp_run = client.run(\n",
    "    \"data_ingestion/spaceeye/spaceeye_interpolation\",\n",
    "    \"Amazon SpaceEye Interpolation 2020\",\n",
    "    geometry=geom,\n",
    "    time_range=time_ranges[2],\n",
    ")\n",
    "se_interp_run.monitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340fee3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for s2 in sorted(runs[2].output[\"raster\"][::2], key=lambda x: x.time_range[0]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    se_raster = sorted(\n",
    "        se_interp_run.output[\"raster\"], key=lambda x: abs(s2.time_range[0] - x.time_range[0])\n",
    "    )[0]\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(s2.time_range[0].strftime(\"%Y-%m-%d\"))\n",
    "    plt.imshow(s2_to_img(read_raster(s2, geom)[0]))\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spaceeye_to_img(read_raster(se_raster)[0]))\n",
    "    plt.title(\"SpaceEye - damped interpolation\")\n",
    "    plt.axis(\"off\")\n",
    "    lw_plot()"
   ]
  }
 ],
 "metadata": {
  "description": "Download and preprocess Sentinel data to obtain cloud-free images using SpaceEye over the Amazon Rainforest.",
  "disk_space": "",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "name": "Investigating Amazon Rainforest deforestation with SpaceEye",
  "running_time": "",
  "tags": [
   "SpaceEye",
   "Sentinel",
   "Remote Sensing"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
