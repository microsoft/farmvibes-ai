{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FarmVibes.AI Crop Segmentation - Dataset Generation\n",
    "\n",
    "This notebook demonstrates how to generate a dataset for crop land segmentation with the FarmVibes.AI platform. The workflow outputs NDVI timeseries and [Crop Data Layer](https://data.nal.usda.gov/dataset/cropscape-cropland-data-layer#:~:text=The%20Cropland%20Data%20Layer%20%28CDL%29%2C%20hosted%20on%20CropScape%2C,as%20well%20as%20boundary%2C%20water%20and%20road%20layers.) (CDL) maps that are used for training a segmentation model in the following notebooks in this repository.\n",
    "\n",
    "As provided, this notebook retrieves and preprocesses a region of ~5,000 kmÂ² over a 1-year period. **We recommend having at least 500 GB of disk space available. The workflow may take multiple days to run, depending on the number of workers and your VM spec.**\n",
    "\n",
    "\n",
    "### Conda environment setup\n",
    "Before running this notebook, let's build a conda environment. If you do not have conda installed, please follow the instructions from [Conda User Guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html). \n",
    "\n",
    "```\n",
    "$ conda env create -f ./crop_env.yaml\n",
    "$ conda activate crop-seg\n",
    "```\n",
    "\n",
    "### Notebook outline\n",
    "The user provides a geographical region and a date range of interest, which are used as input to a FarmVibes.AI workflow that generates the dataset for this task. The workflow consists of downloading and preprocessing Sentinel-2 data, running SpaceEye to obtain cloud-free imagery, and computing daily NDVI indexes at 10m resolution. It also downloads CDL maps in the same time frame at 30m resolution, upsampling them to 10m resolution via nearest neighbor interpolation to be used as ground-truth labels.   \n",
    "\n",
    "In this notebook, we will:\n",
    "- Instantiate FarmVibes.AI client\n",
    "- Load the input geometry and time range from which the workflow will create the dataset\n",
    "- Run the dataset generation workflow\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility imports\n",
    "from datetime import datetime\n",
    "from shapely import wkt\n",
    "\n",
    "# FarmVibes.AI imports\n",
    "from vibe_core.client import get_default_vibe_client\n",
    "\n",
    "# FarmVibes.AI workflow name and description\n",
    "WORKFLOW_NAME = \"ml/dataset_generation/datagen_crop_segmentation\"\n",
    "RUN_NAME = \"dataset generation for crop segmentation task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataset with FarmVibes.AI platform\n",
    "\n",
    "Let's define the region and the time range to consider for this task:\n",
    "- **Region:** FarmVibes.AI platform expects a `.wkt` file with the polygon of the ROI (an example `input_region.wkt` is already provided);\n",
    "- **Time Range:** we define the range as a tuple with two datetimes (start and end dates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_geometry_path = \"./input_region.wkt\"\n",
    "time_range = (datetime(2020, 1, 1), datetime(2020, 12, 31))\n",
    "\n",
    "# Reading the geometry file \n",
    "with open(input_geometry_path) as f:\n",
    "    geometry = wkt.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the crop segmentation task, we will run the `ml/dataset_generation/datagen_crop_segmentation` workflow.\n",
    "\n",
    "To build the dataset, we will instantiate the FarmVibes.AI remote client and run the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the client\n",
    "client = get_default_vibe_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Workflow:</span> <span style=\"color: #005fff; text-decoration-color: #005fff; font-weight: bold; text-decoration: underline\">ml/dataset_generation/datagen_crop_segmentation</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mWorkflow:\u001b[0m \u001b[1;4;38;5;27mml/dataset_generation/datagen_crop_segmentation\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Description:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mDescription:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    Generates a dataset for crop segmentation, based on NDVI raster and Crop Data Layer (CDL) maps. \n",
       "    The workflow generates SpaceEye cloud-free data for the input region and time range and computes\n",
       "    NDVI over those. It also downloads CDL maps for the years comprised in the time range.          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    Generates a dataset for crop segmentation, based on NDVI raster and Crop Data Layer (CDL) maps. \n",
       "    The workflow generates SpaceEye cloud-free data for the input region and time range and computes\n",
       "    NDVI over those. It also downloads CDL maps for the years comprised in the time range.          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Sources:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSources:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">user_input</span> (<span style=\"color: #000080; text-decoration-color: #000080\">vibe_core.data.core_types.DataVibe</span>): Time range and geometry of interest.         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1muser_input\u001b[0m (\u001b[34mvibe_core.data.core_types.DataVibe\u001b[0m): Time range and geometry of interest.         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Sinks:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mSinks:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">ndvi</span> (<span style=\"color: #000080; text-decoration-color: #000080\">vibe_core.data.rasters.Raster</span>): NDVI rasters.                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mndvi\u001b[0m (\u001b[34mvibe_core.data.rasters.Raster\u001b[0m): NDVI rasters.                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">cdl</span> (<span style=\"color: #000080; text-decoration-color: #000080\">vibe_core.data.rasters.CategoricalRaster</span>): CDL map for the years comprised in the input  \n",
       "    time range.                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mcdl\u001b[0m (\u001b[34mvibe_core.data.rasters.CategoricalRaster\u001b[0m): CDL map for the years comprised in the input  \n",
       "    time range.                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Parameters:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mParameters:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">pc_key</span> (<span style=\"color: #000080; text-decoration-color: #000080\">default: task defined</span>): Planetary computer API key.                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mpc_key\u001b[0m (\u001b[34mdefault: task defined\u001b[0m): Planetary computer API key.                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Tasks:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32mTasks:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">spaceeye</span>: Runs the SpaceEye cloud removal pipeline using an interpolation-based algorithm,    \n",
       "    yielding daily cloud-free images for the input geometry and time range.                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mspaceeye\u001b[0m: Runs the SpaceEye cloud removal pipeline using an interpolation-based algorithm,    \n",
       "    yielding daily cloud-free images for the input geometry and time range.                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">ndvi</span>: Computes an index (ndvi, evi, msavi, or methane) from an input raster.                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mndvi\u001b[0m: Computes an index (ndvi, evi, msavi, or methane) from an input raster.                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - <span style=\"font-weight: bold\">cdl</span>: Downloads crop classes maps in the continental USA for the input time range.             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - \u001b[1mcdl\u001b[0m: Downloads crop classes maps in the continental USA for the input time range.             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.document_workflow(WORKFLOW_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow\n",
    "wf_run = client.run(WORKFLOW_NAME, RUN_NAME, geometry=geometry, time_range=time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wf_run` is a `VibeWorkflowRun` that holds the information about the workflow execution. A few of its important attributes:\n",
    "- `wf_run.id`: the ID of the run\n",
    "- `wf_run.status`: indicate the status of the run (pending, running, failed, or done)\n",
    "- `wf_run.workflow`: the name of the workflow being executed (i.e., `WORKFLOW_NAME`)\n",
    "- `wf_run.name`: the description provided by `WORKFLOW_DESC`\n",
    "- `wf_run.output`: the dictionary with outputs produced by the workflow, indexed by sink names\n",
    "\n",
    "In case you need to retrieve a previous workflow run, you can use `client.list_runs()` to list all existing executions and find the id of the desired run. It can be recovered by running `wf_run = client.get_run_by_id(\"ID-of-the-run\")`.\n",
    "\n",
    "We can also use the method `monitor` from `VibeWorkflowRun` to verify the progress of each op/inner workflow of our run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906041aeed614bb18a1ccf0cefa613f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wf_run.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, we can access the generated outputs through `wf_run.output`.\n",
    "\n",
    "The list of outputs of the dataset generation workflow is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access a specific output, we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_rasters = wf_run.output[\"cdl\"]\n",
    "ndvi_rasters = wf_run.output[\"ndvi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "### Next steps\n",
    "\n",
    "Now that we ran the workflow, future runs will retrieve the cached results, allowing for easier and faster experimentation with the data.\n",
    "With the dataset generated, we recommend the following notebooks:\n",
    "- [Visualization Notebook](./02_visualize_dataset.ipynb) shows the intermediate outputs of the workflow, exploring how Sentinel-2 data is processed into the NDVI rasters\n",
    "- [Local Training Notebook](./03_local_training.ipynb) shows how we can perform a local training with the data generated by FarmVibes.AI\n",
    "- [AML Training Notebook](./03_aml_training.ipynb) leverages the computing capabilities of Azure Machine Learning to train the segmentation model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('crop-seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4ed1382910929959896ae46210007cc63f041dd0c6059830101875a13ee5841"
   }
  },
  "name": "Crop land segmentation (1/4) - dataset generation",
  "description": "Generate a dataset based on NDVI and CDL rasters to train a crop land segmentation model.",
  "tags": ["Crop Land Segmentation", "Model Training", "Working with Custom Workflows", "Remote Sensing"],
  "disk_space": "",
  "running_time": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
