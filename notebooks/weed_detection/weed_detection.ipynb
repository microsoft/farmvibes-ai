{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FarmVibes.AI Weed Detection\n",
    "\n",
    "This notebook demonstrates how to run the weed detection workflow on a raster image collected from a drone or satellite. We assume the image is saved in a remote location such as [Azure File Storage](https://azure.microsoft.com/en-us/products/storage/files/#overview).\n",
    "\n",
    "\n",
    "### Conda environment setup\n",
    "Before running this notebook, let's build a conda environment. If you do not have conda installed, please follow the instructions from [Conda User Guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html). \n",
    "\n",
    "```\n",
    "$ conda env create -f ./weed_detection.yaml\n",
    "$ conda activate weed_detection\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook outline\n",
    "The current script in this notebook is configured to download a remote raster image and generate shape files marking similar regions. This is useful in detecting portions of land affected by weeds. The workflow accepts a signed URL to a remote raster image, such as a [shared access signature](https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview) for images stored in Azure, and a geometry for the area of interest. The workflow downloads the raster and trains a Gaussian Mixture Model to group similar regions. The workflow outputs a zip archive with each of the shapefiles defining the partitions.\n",
    "\n",
    "\n",
    "Below are the main libraries used for this example and other useful links:\n",
    "- [NumPy](https://github.com/numpy/numpy) is a python package that provides powerful N-dimensional array object, broadcasting functions and useful linear algebra, Fourier transform, and random number capabilities.\n",
    "- [pandas](https://github.com/scikit-learn/scikit-learn) is a Python package that provides fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive.\n",
    "- [rasterio](https://github.com/rasterio/rasterio) is a library for reading and writing geospatial raster data. It is used on torchgeo and rioxarray. It is a good option when reading/writing GeoTIFFs.\n",
    "- [Scikit-Learn](https://github.com/scikit-learn/scikit-learn) is a Python package for machine learning built on top of SciPy. It Simple and efficient tools for predictive data analysis.\n",
    "- [Shapely](https://github.com/shapely/shapely) is a library for manipulating geometric shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & API Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from vibe_core.client import get_default_vibe_client\n",
    "from vibe_core.data import ExternalReferenceList\n",
    "from datetime import datetime\n",
    "from shapely import geometry as shpg\n",
    "from urllib import request\n",
    "\n",
    "client = get_default_vibe_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the workflow\n",
    "This workflow requires a url for a raster image and a geometry defining the boundaries for the region of interest in the raster image. This cell uses a url and a shapefile to generate the input object passed into the weed detection workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"<SAS URL>\"\n",
    "boundary_shape_file = \"\"\n",
    "\n",
    "now = datetime.now()\n",
    "data_frame = gpd.read_file(boundary_shape_file).to_crs(\"epsg:4326\")\n",
    "assert data_frame is not None\n",
    "geometry = shpg.mapping(data_frame.geometry.iloc[0])\n",
    "url_hash = str(hash(url))\n",
    "\n",
    "inputs = ExternalReferenceList(id=url_hash, time_range=(now, now), geometry=geometry, assets=[], urls=[url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run(workflow='farm_ai/agriculture/weed_detection', name=\"weed_detection_example\", input_data=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Parameters\n",
    "You can specify optional parameters to tailor the computational complexity or the result smoothing to your needs. Options are supplied via the \"parameters\" dictionary when running the workflow. These parameters are:\n",
    "- samples: [int] The number of pixels to sample from the input image. We don’t build the model with all pixels in the image. Rather, we randomly select a subset of pixels to sample when building the model.\n",
    "- buffer: [int] An offset from each edge of the raster that should be ignored by the pipeline\n",
    "- grid_size: [int] This is a tunable parameter for categorizing pixels into regions. This affects workflow speed and memory usage, not the output. Larger grids are generally faster until you reach the device’s memory limit\n",
    "- clusters: [int] This is the number of region classes you would like to identify within the raster. Pixels of the same class may or may not be collocated.\n",
    "- sieve_size: [int] This is the cutoff for determining if a region is too small to be included\n",
    "- simplify: One of [\"none\", \"simplify\", \"convex\"] This is the option for simplifying the borders of regions. Options are: [Convex, Simplify, None]\n",
    "- tolerance: [float] This is the tolerance used in simplification. All parts of a geometry will be no more than tolerance distance from the original. See GeoSeries.simplify for more documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run with configurable parameters\n",
    "# run = client.run(workflow='farm_ai/agriculture/weed_detection', name=\"weed_detection_example\", input_data=inputs, parameters={\"buffer\": -100, \"grid_size\": 250, \"clusters\": 4, \"sieve_size\": 1000,\"tolerance\": 0.25, \"samples\": 150000})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting results\n",
    "The ouput of the workflow contains a zip archive containing a shape file for each cluster of pixels grouped by the GMM. This code extracts the archive path from the DataVibeDict returned from the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.monitor()\n",
    "# Output is a DataVibeDict\n",
    "output = run.output\n",
    "# There was only one input raster to the weed detection workflow so there is only one DataVibe in the result\n",
    "dv = output['result'][0]\n",
    "# The DataVibe output by a weed detection workflow instance has only one asset\n",
    "asset = dv.assets[0]\n",
    "# Get the asset path containing the generated shape files\n",
    "archive_path = asset.path_or_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Output\n",
    "We use matplotlib and geopandas to display the results of the workflow, overlayed on the input raster. This is a quick way to get a high level view the workflow output. To get a more detailed look, we recommend opening the generated files and input raster in a geographic analysis platform, such as [QGIS](https://www.qgis.org/en/site/). This will allow you to zoom in and more closely examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# SAS url or local path to raster\n",
    "raster_file = \"\"\n",
    "\n",
    "# Compute the number of images and layout for plotting\n",
    "num_clusters = len([name for name in ZipFile(archive_path).namelist() if name.endswith('.shp')])\n",
    "width = 3\n",
    "height = num_clusters // width + 1\n",
    "plt.figure(figsize=(30, 30))\n",
    "fig, axs = plt.subplots(height, width)\n",
    "\n",
    "# Remove the axis lables from all subplots\n",
    "for ax in axs.reshape(-1):\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Open the raster image and display it in each subplot\n",
    "raster = rasterio.open(raster_file)\n",
    "for i in range(1, num_clusters + 2):\n",
    "    ax = plt.subplot(height, width, i)\n",
    "    rasterio.plot.show(raster, ax=ax)\n",
    "\n",
    "# read and plot zip archive via geopandas\n",
    "for cluster_num in range(num_clusters):\n",
    "    filename = f\"cluster{cluster_num}.shp\"\n",
    "    zipfile = f\"zip:///{archive_path}!{filename}\"\n",
    "    cluster = gpd.read_file(zipfile)\n",
    "    ax = plt.subplot(height, width, cluster_num + 2)\n",
    "    cluster.plot(ax=ax, color=f'C{9 - cluster_num}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7a6b3d5c3419509e7cd5aed78831540b96cd6bae1b8821a4975470946601923e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
